



    
| Speaker |  Talk| Abstract   |   
|:----------|:----------:|:----------|
| [**Agnese Barbensi**](https://sites.google.com/view/agnesebarbensi/home) (University of Melbourne, Australia)     |   |  ...   |
|  [**Elizabeth Munch**](http://www.elizabethmunch.com/) (Michigan State University, USA) | ... |  ...         | 
|   [**David Gleich**](https://www.cs.purdue.edu/homes/dgleich/) (Purdue University, USA)   | ... | ...          |    
|   [**Jose Perea**](https://www.joperea.com/) (Northeastern University, USA)   | ... |   ...        |    
|  [**Bastian Rieck**](https://bastian.rieck.me/) (AIDOS Lab, Germany)   |  Topology-Based Graph Learning | Topological data analysis is starting to establish itself as a powerful and effective framework in machine learning , supporting the analysis of neural networks, but also driving the development of novel algorithms that incorporate topological characteristics. As a problem class, graph representation learning is of particular interest here, since graphs are inherently amenable to a topological description in terms of their connected components and cycles. This talk will provide an overview of how to address graph learning tasks using machine learning techniques, with a specific focus on how to make such techniques 'topology-aware.' We will discuss how to learn filtrations for graphs and how to incorporate topological information into modern graph neural networks, resulting in provably more expressive algorithms. This talk aims to be accessible to an audience of TDA enthusiasts; prior knowledge of machine learning is helpful but not required.          |    
 |Tamara Kohler  |  Quantum complexity classes and topological data analysis | Recently progress has been made on the long-standing question of the computational complexity of determining homology groups of simplicial complexes, a fundamental task in computational topology, posed by Kaibel and Pfetsch 20 years ago. It was shown that the complexity of versions of the problem is closely linked to quantum complexity classes, suggesting that this seemingly classical problem may in fact be quantum. In this talk I explain why this problem in topology should have anything to do with quantum mechanics, and give an overview of recent results on the complexity of homology. I will discuss what these results suggest for the possibility of quantum advantage in topological data analysis, and open questions. |
  | Colleen M. Farrelly | Hands-On Workshop Series: Forman-Ricci Curvature Applications, BERT, Metric Geometry, and Persistent Homology  | Depending time, we'll 1) overview Forman-Ricci curvature and apply it to social network, spatial, and spatiotemporal data; 2) examine how word embeddings wrangle text data into supervised learning pipelines; 3) explore metric geometry and nearest neighbors algorithms to see how local properties of manifolds impact prediction accuracy; and 4) apply persistent homology to identify transition points in time series data. Most tutorials will be in Python (except #4, which will be in R). Notebooks and data will be provided so students can follow along. |
   | Vanessa Robins | Topological Data Analysis: Introduction and Application  |  Topological Data Analysis has grown out of work focussed on deriving qualitative and yet quantifiable information about the shape of data. The underlying assumption is that knowledge of shape - the way the data are distributed in a space - permits high-level reasoning and modelling of the processes that created this data. The 0-th order aspect of shape is the number pieces: “connected components” to a topologist; “clustering” to a statistician. Higher-order topological aspects of shape are holes, quantified as “non-bounding cycles” in homology theory. These signal the existence of some type of constraint on the data- generating process. Homology lends itself naturally to computer implementation, but its naive application is not robust to perturbations. This inspired the development of persistent homology: an algebraic topological tool that measures changes in the topology of a growing sequence of spaces (a filtration). Persistent homology provides invariants called the barcodes or persistence diagrams that are sets of intervals recording the birth and death parameter values of each homology class in the filtration. It captures information about the shape of data over a range of length scales and enables a distinction between noisy and significant structures that is continuous with respect to perturbation.  This rich geometric summary has found application in fields ranging from astrophysics to materials science and biostatistics.|
 | Sean Andrew Thawe | How To Get Started in Quantum Computing   |  Quantum computers aren’t the next generation of supercomputers but rather they are something else entirely. At the same time quantum computers aren’t developing in isolation of classical computing. Basically, when we look at classical computing at the unit level it stores information in bits. Which is binary, meaning two bits – or two states. Something with two states carries less amount of information. A bit is the smallest unit of classical computation and classical information. Quantum computation and quantum information are built on an analogous concept, the quantum bit, or qubit for short. Just like bits in classical computing, qubits are the core components in quantum computing.  As technology advances into A.I. and ML we find that training models requires quite huge amounts of data. Speeding up the process requires parallelizing the data processing as much as possible. Now with GPU – computer graphics card – its proving to help quite a lot. At the same time, it takes an exponential amount of data to solve the problem and that’s not a good thing, in turn that will mean an exponential number of operations to manipulate them is need. Data parallelization improves performance linearly so it is not a cure for problems with exponential complexity. Quantum computers may have its constraints but like any other technologies it has got Its own advantages. Quantum computers offer us entanglement and interference. Another advantage is superposition. Superposition is the reason that quantum computers can store and manipulate vast amounts of data compare to classical computers.  With superposition, we can encode an exponential amount of information that can scale a solution better than classical computing. There are several ways one can get started in quantum computing and also end up in Quantum Machine Learning. Quantum computing may have a lot to offer but it is still at its infancy stage. Another field developing in quantum computing is Quantum Machine Learning, which is still a theoretical field at the moment. It lies at the intersection quantum computing and machine learning.|
     | Carlo Maria Scandolo |  The power of quantum resources | Resource theories are a powerful framework for studying several phenomena in quantum information. In this talk, I present some of my latest research results in this area, showing how resource theories can be fruitfully employed to open new research directions, both in quantum information and beyond. |
      |  |   |  |
       |  |   |  |
